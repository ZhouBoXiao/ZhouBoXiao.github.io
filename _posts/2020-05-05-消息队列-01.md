---
layout:     post
title:      "消息队列"
subtitle:   "消息队列相关知识01"
date:       2020-05-05
author:     "ZBX"
header-img: "img/tag-bg.jpg"
tags:
    - MQ
---

## 如何保证消息队列的高可用

1. rabbitmq有三种模式：单机模式，普通集群模式，镜像集群模式

2. kafka的高可用性
   1. 多个broker组成，每个broker是一个节点；你创建一个topic，这个topic可以划分为多个partition，每个partition可以存在于不同的broker上，每个partition就放一部分数据。
   2. replica副本机制。每个partition的数据都会同步到吉他机器上，形成自己的多个replica副本。

## 如何保证消息不被重复消费

1. kafka中，每个消息写进去，都有一个offset来代表它的序号，然后consumer消费了数据之后，每隔一段时间，会把自己消费过的消息的offset提交一下，代表我已经消费过了。
2. 需要让生产者发送每条数据的时候，里面加一个全局唯一的id，类似订单id之类的东西，然后你这里消费到了之后，先根据这个id去比如redis里查一下，之前消费过吗？如果没有消费过，你就处理，然后这个id写redis。

## 如何保证消息的可靠性传输

### RabbitMQ

1. 生产者丢数据
   1. 如果你要确保说写rabbitmq的消息别丢，可以开启confirm模式，在生产者那里设置开启confirm模式之后，你每次写的消息都会分配一个唯一的id，然后如果写入了rabbitmq中，rabbitmq会给你回传一个ack消息，告诉你说这个消息ok了。如果rabbitmq没能处理这个消息，会回调你一个nack接口，告诉你这个消息接收失败，你可以重试。而且你可以结合这个机制自己在内存里维护每个消息id的状态，如果超过一定时间还没接收到这个消息的回调，那么你可以重发。
2. rabbitmq弄丢了数据
   1. 开启rabbitmq的持久化
3. 消费端弄丢了数据
   1. 关闭rabbitmq自动ack，可以通过一个api来调用就行，然后每次你自己代码里确保处理完的时候，再程序里ack一把。

### Kafka

1. 生产者会不会弄丢数据
2. kafka弄丢了数据
   1. 某个broker宕机，然后重新选举partiton的leader时
3. 消费端弄丢了数据
   1. 只要关闭自动提交offset，在处理完之后自己手动提交offset，就可以保证数据不会丢。

## 如何保证消息的顺序性

kafka：一个topic，一个partition，一个consumer，内部单线程消费，写N个内存queue，然后N个线程分别消费一个内存queue即可

## 有几百万消息持续积压几小时，说说怎么解决

1. 先修复consumer的问题，确保其恢复消费速度，然后将现有cnosumer都停掉

2. 新建一个topic，partition是原来的10倍，临时建立好原先10倍或者20倍的queue数量

3. 然后写一个临时的分发数据的consumer程序，这个程序部署上去消费积压的数据，消费之后不做耗时的处理，直接均匀轮询写入临时建立好的10倍数量的queue

4. 接着临时征用10倍的机器来部署consumer，每一批consumer消费一个临时queue的数据

## 设计消息队列系统

1. mq得支持可伸缩性
2. 持久化操作
3. 高可用
4. 防止数据的丢失